{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-d2fe62d53a9d>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-d2fe62d53a9d>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Los joins son una parte fundamental en el trabajo con multiples tablas\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Los joins son una parte fundamental en el trabajo con multiples tablas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "from pyspark.conf import SparkConf\n",
    "import pyspark.sql.functions as func\n",
    "\n",
    "from IPython.display import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an spark session\n",
    "spark_conf = SparkConf().setAppName('joins')\n",
    "spark_conf.set('spark.jars.packages', 'org.apache.hadoop:hadoop-aws:2.7.3,org.postgresql:postgresql:9.4.1211')\n",
    "spark = SparkSession.builder.config(conf=spark_conf).getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_1 = [(\"juan\",\"2\"),(\"camilo\",\"4\"),(\"cristian\",\"4\"),(\"luz\",\"2\")]\n",
    "df1 = spark.createDataFrame(list_1, [\"name\",\"total\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|    name|total|\n",
      "+--------+-----+\n",
      "|    juan|    2|\n",
      "|  camilo|    4|\n",
      "|cristian|    4|\n",
      "|     luz|    2|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_2 = [(\"juan\",\"4\"),(\"andres\",\"4\"),(\"cristian\",\"3\"),(\"luz\",\"2\"),(\"david\",\"5\")]\n",
    "df2 = spark.createDataFrame(list_2, [\"name\",\"total\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|    name|total|\n",
      "+--------+-----+\n",
      "|    juan|    4|\n",
      "|  andres|    4|\n",
      "|cristian|    3|\n",
      "|     luz|    2|\n",
      "|   david|    5|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|    name|total|\n",
      "+--------+-----+\n",
      "|   david|    5|\n",
      "|cristian|    3|\n",
      "|     luz|    2|\n",
      "|    juan|    4|\n",
      "|  andres|    4|\n",
      "|  camilo|    4|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3 = df1.alias(\"df1\").join(df2.alias(\"df2\"), [\"name\"], how=\"full\")#.select(\"name, COALESCE(df2.total, df1.total)\").show()\n",
    "df3 = df3.withColumn('c', func.coalesce(df3['df2.total'],df3['df1.total'])).selectExpr(\"name\",\"c as total\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.alias(\"df1\").join(df2.alias(\"df2\"), [\"name\"], how=\"full\").where(\"df1.total is not null\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|    name|total|\n",
      "+--------+-----+\n",
      "|    juan|    2|\n",
      "|  camilo|    4|\n",
      "|cristian|    4|\n",
      "|     luz|    2|\n",
      "|    juan|    4|\n",
      "|  andres|    4|\n",
      "|cristian|    3|\n",
      "|     luz|    2|\n",
      "|   david|    5|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.union(df2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|  name|total|\n",
      "+------+-----+\n",
      "| david|    5|\n",
      "|andres|    4|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.join(df1, df1.name == df2.name, how=\"left_anti\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "podemos trabajar con las dos tablas usando los diferentes tipos de joins. Cada join debera recibir el parametro de la llave o llaves por las que se quiere comparar las tablas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+-----+\n",
      "|    name|total|total|\n",
      "+--------+-----+-----+\n",
      "|cristian|    4|    3|\n",
      "|     luz|    2|    2|\n",
      "|    juan|    2|    4|\n",
      "+--------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.join(df2, \"name\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "por defecto se realizara un lef join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "si entre las tablas la llave sobre la que se quiere realizar el join, se tiene un nombre diferente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+--------+-----+\n",
      "|    name|total|    name|total|\n",
      "+--------+-----+--------+-----+\n",
      "|cristian|    4|cristian|    3|\n",
      "|     luz|    2|     luz|    2|\n",
      "|    juan|    2|    juan|    4|\n",
      "+--------+-----+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.join(df2, df1.name == df2.name).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "para realizar el join se puede especificar el tipo de join "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "en general vamos a encontrar 6 tipos de joins:\n",
    "\n",
    "· FULL OUTER / OUTER / FULL\n",
    "    \n",
    "· INNER\n",
    "\n",
    "· LEFT OUTER / LEFT\n",
    "\n",
    "· RIGHT OUTER / RIGHT\n",
    "\n",
    "· LEFT SEMI\n",
    "\n",
    "· LEFT ANTI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FULL: \n",
    "    Combinara las dos tablas, dando como resultado un nuevo df donde las llaves coinciden y existen, es decir no retornara un null\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/gif": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(\"https://www.w3schools.com/sql/img_fulljoin.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+-----+\n",
      "|    name|total|total|\n",
      "+--------+-----+-----+\n",
      "|   david| null|    5|\n",
      "|cristian|    4|    3|\n",
      "|     luz|    2|    2|\n",
      "|    juan|    2|    4|\n",
      "|  andres| null|    4|\n",
      "|  camilo|    4| null|\n",
      "+--------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.join(df2, [\"name\"], how=\"full\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "\"cannot resolve '`df1.total`' given input columns: [name, total, total]; line 1 pos 0;\\n'Filter NOT ('df1.total = null)\\n+- AnalysisBarrier\\n      +- Project [coalesce(name#0, name#12) AS name#79, total#1, total#13]\\n         +- Join FullOuter, (name#0 = name#12)\\n            :- LogicalRDD [name#0, total#1], false\\n            +- LogicalRDD [name#12, total#13], false\\n\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o74.filter.\n: org.apache.spark.sql.AnalysisException: cannot resolve '`df1.total`' given input columns: [name, total, total]; line 1 pos 0;\n'Filter NOT ('df1.total = null)\n+- AnalysisBarrier\n      +- Project [coalesce(name#0, name#12) AS name#79, total#1, total#13]\n         +- Join FullOuter, (name#0 = name#12)\n            :- LogicalRDD [name#0, total#1], false\n            +- LogicalRDD [name#12, total#13], false\n\n\tat org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:42)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$2.applyOrElse(CheckAnalysis.scala:88)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$2.applyOrElse(CheckAnalysis.scala:85)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$1.apply(TreeNode.scala:289)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$1.apply(TreeNode.scala:289)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:70)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:288)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:286)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:286)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:306)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:304)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:286)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:286)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:286)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:306)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:304)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:286)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$transformExpressionsUp$1.apply(QueryPlan.scala:95)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$transformExpressionsUp$1.apply(QueryPlan.scala:95)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$1.apply(QueryPlan.scala:107)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$1.apply(QueryPlan.scala:107)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:70)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpression$1(QueryPlan.scala:106)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1(QueryPlan.scala:118)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$2.apply(QueryPlan.scala:127)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.mapExpressions(QueryPlan.scala:127)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpressionsUp(QueryPlan.scala:95)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:85)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:80)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:127)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$class.checkAnalysis(CheckAnalysis.scala:80)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:92)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:105)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:57)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:55)\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:47)\n\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:172)\n\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:178)\n\tat org.apache.spark.sql.Dataset$.apply(Dataset.scala:65)\n\tat org.apache.spark.sql.Dataset.withTypedPlan(Dataset.scala:3301)\n\tat org.apache.spark.sql.Dataset.filter(Dataset.scala:1458)\n\tat org.apache.spark.sql.Dataset.filter(Dataset.scala:1472)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-c7bbb5a3d85e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"full\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"df1.total != null\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mfilter\u001b[0;34m(self, condition)\u001b[0m\n\u001b[1;32m   1238\u001b[0m         \"\"\"\n\u001b[1;32m   1239\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1240\u001b[0;31m             \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1241\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m             \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     67\u001b[0m                                              e.java_exception.getStackTrace()))\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.AnalysisException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.catalyst.analysis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: \"cannot resolve '`df1.total`' given input columns: [name, total, total]; line 1 pos 0;\\n'Filter NOT ('df1.total = null)\\n+- AnalysisBarrier\\n      +- Project [coalesce(name#0, name#12) AS name#79, total#1, total#13]\\n         +- Join FullOuter, (name#0 = name#12)\\n            :- LogicalRDD [name#0, total#1], false\\n            +- LogicalRDD [name#12, total#13], false\\n\""
     ]
    }
   ],
   "source": [
    "df1.join(df2, [\"name\"], how=\"full\").where(\"df1.total != null\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+-----+\n",
      "|    name|total|total|\n",
      "+--------+-----+-----+\n",
      "|cristian|    4|    3|\n",
      "|     luz|    2|    2|\n",
      "|    juan|    2|    4|\n",
      "|  camilo|    4| null|\n",
      "+--------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.alias(\"df1\").join(df2.alias(\"df2\"), [\"name\"], how=\"full\").where(\"df1.total is not null\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|name|total|total|\n",
      "+----+-----+-----+\n",
      "| luz|    2|    2|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.alias(\"df1\").join(df2.alias(\"df2\"), [\"name\"], how=\"full\").where(\"df1.total == df2.total\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|name|total|total|\n",
      "+----+-----+-----+\n",
      "| luz|    2|    2|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.alias(\"df1\").join(df2.alias(\"df2\"), [\"name\"], how=\"full\").where(\"df1.total == df2.total\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+-----+\n",
      "|    name|total|total|\n",
      "+--------+-----+-----+\n",
      "|   david| null|    5|\n",
      "|cristian|    4|    3|\n",
      "|     luz|    2|    2|\n",
      "|    juan|    2|    4|\n",
      "|  andres| null|    4|\n",
      "|  camilo|    4| null|\n",
      "+--------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.join(df2, [\"name\"], how=\"full_outer\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INNER: \n",
    "    Combinara las dos tablas, dando como resultado un nuevo df donde las llaves coinciden y existen, es decir no retornara un null\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Image(\"https://www.w3schools.com/sql/img_innerjoin.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.join(df2, [\"name\"], how=\"inner\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joins = (\"inner\", \"outer\", \"full\", \"full_outer\", \"left\", \"left_outer\", \"right\", \n",
    "         \"right_outer\", \"left_semi\", \"left_anti\")\n",
    "#joins = (\"left_semi\", \"left_anti\")\n",
    "\n",
    "for join_type in joins:\n",
    "    print(join_type.upper())\n",
    "    df_1.join(df_2, [\"name\"], how=join_type).show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3 = df_1.join(df_2, [\"name\"], how=\"full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new elements\n",
    "df_3.filter(df_1.total.isNull()).drop(df_1.total).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# element to update\n",
    "df_3.where(df_1.total != df_2.total).drop(df_1.total).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# elements withouth changes\n",
    "df_3.where(df_1.total == df_2.total).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_df1 = df1.select(\"name\")\n",
    "n_df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_df2 = df2.select(\"name\")\n",
    "n_df2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "al considerar n_df2 como un listado de nuevos elementos, para determinar quienes son los nuevos que antes no estaban en n_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n_df2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-038bc224d604>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mn_df2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_df1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"left_anti\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'n_df2' is not defined"
     ]
    }
   ],
   "source": [
    "n_df2.join(n_df1, [\"name\"], how=\"left_anti\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_11 = [(\"juan\",\"2\",\"r\"),(\"juan\",\"1\",\"p\"),(\"juan\",\"3\",\"q\"),(\"camilo\",\"1\",\"rr\"),(\"cristian\",\"4\",\"pp\")]\n",
    "m_df1 = spark.createDataFrame(list_11, [\"name\",\"total\",\"val\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+---+\n",
      "|    name|total|val|\n",
      "+--------+-----+---+\n",
      "|    juan|    2|  r|\n",
      "|    juan|    1|  p|\n",
      "|    juan|    3|  q|\n",
      "|  camilo|    1| rr|\n",
      "|cristian|    4| pp|\n",
      "+--------+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "m_df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_12 = [(\"m\",\"1\"),(\"m\",\"2\"),(\"m\",\"3\"),(\"m\",\"4\")]\n",
    "m_df2 = spark.createDataFrame(list_12, [\"name\",\"total\"]).select(\"total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|total|\n",
      "+-----+\n",
      "|    1|\n",
      "|    2|\n",
      "|    3|\n",
      "|    4|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "m_df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "piv = m_df1.select(\"name\").distinct().crossJoin(m_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+----+\n",
      "|    name|total| val|\n",
      "+--------+-----+----+\n",
      "|    juan|    2|   r|\n",
      "|cristian|    4|  pp|\n",
      "|  camilo|    3|null|\n",
      "|    juan|    1|   p|\n",
      "|  camilo|    4|null|\n",
      "|cristian|    3|null|\n",
      "|  camilo|    1|  rr|\n",
      "|    juan|    3|   q|\n",
      "|    juan|    4|null|\n",
      "|  camilo|    2|null|\n",
      "|cristian|    1|null|\n",
      "|cristian|    2|null|\n",
      "+--------+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "piv.join(m_df1, [\"name\",\"total\"], how=\"left_outer\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
